{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 2.2.2\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [ \"matplotlib\", \"numpy\", \"tiktoken\", \"torch\"]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataSet Class  for martin-gpt\n",
    "\n",
    "class GPT_Dataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids =  []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128,\n",
    "                         shuffle=True, drop_last=True, num_workers=0):\n",
    "    \n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    \n",
    "    dataset = GPT_Dataset(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "                            drop_last=drop_last, num_workers=num_workers)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads \n",
    "        \n",
    "        self.w_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        \n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        queries = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "        \n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        \n",
    "        keys = keys.transpose(1,2)\n",
    "        queries = queries.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "        \n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2,3)\n",
    "        \n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        \n",
    "        context_vec = (attn_weights @ values).transpose(1,2)\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        \n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True)\n",
    "        norm_x = ( x - mean ) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim * 4),\n",
    "            GELU(), \n",
    "            nn.Linear(emb_dim * 4, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.att = MultiHeadAttention(d_in=cfg[\"emb_dim\"],\n",
    "                                      d_out=cfg[\"emb_dim\"],\n",
    "                                      context_length=cfg[\"context_length\"],\n",
    "                                      dropout=cfg[\"drop_rate\"],\n",
    "                                      num_heads=cfg[\"n_heads\"],\n",
    "                                      qkv_bias=cfg[\"qkv_bias\"]) \n",
    "        self.ff = FeedForward(cfg[\"emb_dim\"])\n",
    "        self.norm_1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm_2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        shortcut = x\n",
    "        \n",
    "        x = self.norm_1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x \n",
    "        x = self.norm_2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        \n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        \n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "            \n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=-1)\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=-1)\n",
    "        \n",
    "    return idx\n",
    "\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        \n",
    "        GPT_CONFIG = {\n",
    "            \"vocab_size\": 50257,\n",
    "            \"context_length\": 1024,\n",
    "            \"emb_dim\": 768,\n",
    "            \"n_heads\": 12,\n",
    "            \"n_layers\": 12,\n",
    "            \"drop_rate\": 0.1,\n",
    "            \"qkv_bias\": False,\n",
    "        }\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        model = GPTModel(GPT_CONFIG)\n",
    "        model.eval() \n",
    "        \n",
    "        start_context = \"Hello, I am\" \n",
    "        \n",
    "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "        encoded = tokenizer.encode(start_context)\n",
    "        encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "        \n",
    "        print(f\"\\n{50*'='}\\n{22*' '}IN\\n{50*'='}\")\n",
    "        print(\"\\nInput text:\", start_context)\n",
    "        print(\"Encoded input text:\", encoded)\n",
    "        print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "\n",
    "        out = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded_tensor,\n",
    "            max_new_tokens=10,\n",
    "            context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "        )\n",
    "        decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "\n",
    "        print(f\"\\n\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
    "        print(\"\\nOutput:\", out)\n",
    "        print(\"Output length:\", len(out[0]))\n",
    "        print(\"Output text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you renting rentinguffuffmondmondrunnerrunnerWrWr � �\u000e\u000e lists lists Parish Parish Cooperative Cooperative\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# token_ids = text_to_token_ids(start_context, tokenizer)\n",
    "# token_ids = torch.tensor(token_ids).to(device)\n",
    "\n",
    "\n",
    "# token_ids = generate_text_simple(\n",
    "#     model=model,\n",
    "#     idx=text_to_token_ids(start_context, tokenizer),\n",
    "#     max_new_tokens=10,\n",
    "#     context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "# )\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(f\"Total characters: {total_characters}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECK\n",
    "\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten()) \n",
    "    return loss \n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.98738521999783\n",
      "Validation loss: 10.980905532836914\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Train loss: {train_loss}\")\n",
    "print(f\"Validation loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    #main training loop \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "        \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                \n",
    "                print(f\"Epoch: {epoch+1} | \"\n",
    "                      f\"Global Step: {global_step:06d} | \"\n",
    "                      f\"Tokens Seen: {tokens_seen:09d} | \"\n",
    "                      f\"Train Loss: {train_loss:.3f} | \"\n",
    "                      f\"Validation Loss: {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "    \n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Global Step: 000000 | Tokens Seen: 000000512 | Train Loss: 9.784 | Validation Loss: 9.928\n",
      "Epoch: 1 | Global Step: 000005 | Tokens Seen: 000003072 | Train Loss: 7.986 | Validation Loss: 8.336\n",
      "Every Effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,..      \n",
      "Training took 1.0449422001838684 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  Training the model \"\"\"\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs,\n",
    "    eval_freq=5, eval_iter=5, start_context=\"Every Effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "print(f\"Training took {(end_time - start_time)/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
